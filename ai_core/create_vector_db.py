# This script creates the vector database using FAISS, which is more
# reliable on Windows as it doesn't require a C++ compiler.
# It imports its knowledge from the 'curated_knowledge.py' file.
from sentence_transformers import SentenceTransformer
from langchain_community.embeddings import HuggingFaceEmbeddings # <-- IMPORT THE ADAPTER
from langchain_community.vectorstores import FAISS

# --- 1. Import the Curated Knowledge ---
# Make sure you have 'curated_knowledge.py' in the same 'ai_core' folder.
try:
    from curated_knowledge import knowledge
except ImportError:
    print("âŒ ERROR: Could not find 'ai_core/curated_knowledge.py'. Please create it first.")
    exit()

print("--- ðŸ§  Initializing FAISS Vector Store ---")
print(f"âœ… Successfully imported {len(knowledge)} knowledge documents.")

try:
    # --- 2. Initialize the Embedding Model using the LangChain Adapter ---
    print("Loading embedding model (this might take a moment on first run)...")
    model_name = "sentence-transformers/all-MiniLM-L6-v2"
    embedding_model = HuggingFaceEmbeddings(model_name=model_name)
    print("âœ… Embedding model loaded.")

    # --- 3. Create the FAISS Vector Store in Memory ---
    # This single command takes our knowledge documents, uses the embedding model
    # to convert them to vectors, and builds the FAISS index.
    print("Creating FAISS vector store from knowledge documents...")
    vector_store = FAISS.from_texts(texts=knowledge, embedding=embedding_model)
    print("âœ… FAISS vector store created successfully.")

    # --- 4. Save the Vector Store to a Local Folder ---
    # This saves the index to disk so we can load it later without rebuilding it.
    # It will create a folder named 'faiss_index' in the 'ai_core' directory.
    vector_store.save_local("ai_core/faiss_index")
    
    print(f"\nâœ… SUCCESS: Successfully saved FAISS index to the 'ai_core/faiss_index' folder!")
    print("\n--- AI Knowledge Base Created ---")

except Exception as e:
    print(f"\nâŒ An error occurred: {e}")
